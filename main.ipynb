{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c082db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from src.commentsProcessing import CommentsPreparation\n",
    "from src.employeesProcessing import EmployeesPreparation\n",
    "from src.baseProcessing import createTimeFeatures, createAuxiliaryFeatures, inverseBoxCox, Embeddings, frequencyTables,\\\n",
    "diffFeaturesByGroups, diffFeatures, posFreqEstimation, coeffPositionsInProjects, validateModel, lemmatizeSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8654bd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[device]: cuda\n"
     ]
    }
   ],
   "source": [
    "with open(\"links.json\", \"r\") as file:\n",
    "    links = json.load(file)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[device]: {device}\")    \n",
    "    \n",
    "del file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb0a37",
   "metadata": {},
   "source": [
    "## GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ec3b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salary_calculation_type', 'english_level', 'full_name', 'passport'] were dropped\n",
      "[dfEmp] : (343, 4)\n"
     ]
    }
   ],
   "source": [
    "dfEmp = EmployeesPreparation(links[\"auxiliary\"][\"employees\"], naLimit=0.5).apply()\n",
    "print(f\"[dfEmp] : {dfEmp.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9376d9",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9223fb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[byAuthor] : (52, 9) \n",
      "[byIssue]: (3945, 2)\n"
     ]
    }
   ],
   "source": [
    "byAuthor, byIssue, _ = CommentsPreparation(links[\"train\"][\"comments\"]).apply()\n",
    "print(f\"[byAuthor] : {byAuthor.shape} \\n[byIssue]: {byIssue.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc197e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfTrainIssues]: (9589, 8)\n"
     ]
    }
   ],
   "source": [
    "dfTrainIssues = pd.read_csv(links[\"train\"][\"issues\"])\n",
    "dfTrainIssues[\"summary\"] = dfTrainIssues[\"summary\"].str.lower()\n",
    "dfTrainIssues[\"overall_worklogs\"] = np.log1p(dfTrainIssues[\"overall_worklogs\"])\n",
    "print(f\"[dfTrainIssues]: {dfTrainIssues.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbafa524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9589it [06:20, 25.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:27<00:00,  3.87s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:13<00:00,  1.97s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9589, 58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dfTrainIssues = lemmatizeSummary(dfTrainIssues)\n",
    "dfTrainIssues = dfTrainIssues.merge(byAuthor, on=\"assignee_id\", how=\"left\").fillna(0)\n",
    "dfTrainIssues = dfTrainIssues.merge(byIssue, on=\"id\", how=\"left\").fillna(0)\n",
    "dfTrainIssues = dfTrainIssues.merge(dfEmp.rename(columns={\"id\": \"assignee_id\"}), on=\"assignee_id\", how=\"left\")\n",
    "dfTrainIssues = coeffPositionsInProjects(dfTrainIssues)\n",
    "dfTrainIssues = posFreqEstimation(dfTrainIssues)\n",
    "dfTrainIssues = createTimeFeatures(dfTrainIssues)\n",
    "dfTrainIssues = frequencyTables(dfTrainIssues)\n",
    "dfTrainIssues = diffFeaturesByGroups(dfTrainIssues)\n",
    "dfTrainIssues = diffFeatures(dfTrainIssues)\n",
    "dfTrainIssues = createAuxiliaryFeatures(dfTrainIssues)\n",
    "print(dfTrainIssues.shape)\n",
    "\n",
    "del byAuthor, byIssue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae39403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summary', 'pos', 'time', 'created']\n",
      "(9589, 54)\n"
     ]
    }
   ],
   "source": [
    "objectCols = [col for col in list(dfTrainIssues) if dfTrainIssues[col].dtype == \"object\"]\n",
    "objectCols.remove(\"summary_l\")\n",
    "objectCols.append(\"created\")\n",
    "print(objectCols)\n",
    "\n",
    "dfTrainIssues.drop(objectCols, axis=1, inplace=True)\n",
    "print(dfTrainIssues.shape)\n",
    "\n",
    "del objectCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3142b919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1070it [00:12, 88.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10659, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dfTestIssues = pd.read_csv(links[\"test\"][\"issues\"])\n",
    "dfTestIssues[\"summary\"] = dfTestIssues[\"summary\"].str.lower()\n",
    "dfTestIssues = lemmatizeSummary(dfTestIssues)\n",
    "\n",
    "vec = pd.concat([dfTrainIssues[\"summary_l\"].to_frame(), dfTestIssues[\"summary_l\"].to_frame()]).reset_index(drop=True)\n",
    "print(vec.shape)\n",
    "\n",
    "del dfTestIssues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e342399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10659, 1073)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False, ngram_range=(1,3), min_df=0.001, max_df=1.0, dtype=\"float32\", binary=False,\n",
    "                            stop_words={\"is\", \"by\", \"for\", \"from\", \"in\", \"the\", \"to\", \"of\", \"on\", \"do\", \"does\", \"has\",\n",
    "                                        \"to\", \"на\", \"по\", \"для\", \"with\", \"and\", \"into\", \"have\", \"our\", \"was\", \"we\",\n",
    "                                        \"my\", \"an\", \"about\", \"are\", \"as\", \"at\", \"be\", \"can\" \"you\", \"your\", \"за\", \"из\",\n",
    "                                        \"от\", \"со\", \"a\", \"or\", \"don't\", \"в\", \"и\"})\n",
    "tfidf = vectorizer.fit_transform(vec[\"summary_l\"])\n",
    "tfidfDf = pd.DataFrame(columns=vectorizer.get_feature_names(), data=tfidf.toarray())\n",
    "tfidfDf.drop([col for col in list(tfidfDf) if col[0].isdigit()], axis=1, inplace=True)\n",
    "tfidfDf[\"id\"] = list(range(10659))\n",
    "tfidfDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f91370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9589, 1126)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dfTrainIssues = dfTrainIssues.merge(tfidfDf[:9589], on=\"id\", how=\"left\").fillna(0)\n",
    "print(dfTrainIssues.shape)\n",
    "print(dfTrainIssues.isna().sum().sum())\n",
    "\n",
    "dfTrainIssues.drop([col for col in list(dfTrainIssues) if dfTrainIssues[col].dtype == \"object\"], axis=1, inplace=True)\n",
    "dfTrainIssues.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d277bdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9589/9589 [00:39<00:00, 243.63it/s]\n",
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9589/9589 [02:30<00:00, 63.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# LANG MODELS\n",
    "\n",
    "dfTrainLang = pd.read_csv(links[\"train\"][\"issues\"])\n",
    "dfTrainLang[\"summary\"] = dfTrainLang[\"summary\"].str.lower()\n",
    "dfTrainLang[\"overall_worklogs\"] = np.log1p(dfTrainLang[\"overall_worklogs\"])\n",
    "\n",
    "langModels = [\"cointegrated/rubert-tiny2\", \"cointegrated/LaBSE-en-ru\"]\n",
    "\n",
    "for model in langModels:\n",
    "    dfTrainLang = dfTrainLang.join(Embeddings(dfTrainLang, model, \"summary\", device).apply())\n",
    "    \n",
    "dfTrainLang.drop([\"created\", \"key\", \"summary\", \"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ce504",
   "metadata": {},
   "source": [
    "<h1>MODEL VALIDATION</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080ae24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X]: (9589, 1122) \n",
      "[y]: (9589,)\n",
      "[0]: 0.24052749712426935\n",
      "[1]: 0.24485025676406413\n",
      "[2]: 0.25844370309613995\n",
      "[3]: 0.25834471026050554\n",
      "[4]: 0.2426581043226791\n",
      "[mean]: 0.2489648543135316\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor(iterations=1000, random_seed=42, task_type=\"CPU\",\n",
    "                          eval_metric=\"R2\", use_best_model=False, cat_features=[\"project_id\", \"assignee_id\", \"creator_id\"])\n",
    "validateModel(model, dfTrainIssues, \"overall_worklogs\", fitParams={\"early_stopping_rounds\": 100, \"verbose\": 0},\n",
    "              nFold=5, KFold_randomState=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de8b997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X]: (9589, 1083) \n",
      "[y]: (9589,)\n",
      "[0]: 0.23732914708753583\n",
      "[1]: 0.22623000047222286\n",
      "[2]: 0.23400867015214166\n",
      "[3]: 0.20958566475528617\n",
      "[4]: 0.2565743442720856\n",
      "[mean]: 0.23274556534785443\n"
     ]
    }
   ],
   "source": [
    "# LANG MODELS\n",
    "model = CatBoostRegressor(iterations=1000, random_seed=42, task_type=\"CPU\",\n",
    "                          eval_metric=\"R2\", use_best_model=False, cat_features=[\"project_id\", \"assignee_id\", \"creator_id\"])\n",
    "validateModel(model, dfTrainLang, \"overall_worklogs\", fitParams={\"early_stopping_rounds\": 100, \"verbose\": 0},\n",
    "              nFold=5, KFold_randomState=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b1420",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3656c893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[byAuthor] : (27, 9) \n",
      "[byIssue]: (479, 2)\n"
     ]
    }
   ],
   "source": [
    "byAuthorTest, byIssueTest, _ = CommentsPreparation(links[\"test\"][\"comments\"]).apply()\n",
    "print(f\"[byAuthor] : {byAuthorTest.shape} \\n[byIssue]: {byIssueTest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9bec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dfTestIssues]: (1070, 7)\n"
     ]
    }
   ],
   "source": [
    "dfTestIssues = pd.read_csv(links[\"test\"][\"issues\"])\n",
    "dfTestIssues[\"summary\"] = dfTestIssues[\"summary\"].str.lower()\n",
    "print(f\"[dfTestIssues]: {dfTestIssues.shape}\")\n",
    "\n",
    "dfId = dfTestIssues[\"id\"].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb71d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1070it [00:11, 93.98it/s] \n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  4.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  4.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dfTestIssues = lemmatizeSummary(dfTestIssues)\n",
    "dfTestIssues = dfTestIssues.merge(byAuthorTest, on=\"assignee_id\", how=\"left\").fillna(0)\n",
    "dfTestIssues = dfTestIssues.merge(byIssueTest, on=\"id\", how=\"left\").fillna(0)\n",
    "dfTestIssues = dfTestIssues.merge(dfEmp.rename(columns={\"id\": \"assignee_id\"}), on=\"assignee_id\", how=\"left\")\n",
    "dfTestIssues = coeffPositionsInProjects(dfTestIssues)\n",
    "dfTestIssues = posFreqEstimation(dfTestIssues)\n",
    "dfTestIssues = createTimeFeatures(dfTestIssues)\n",
    "dfTestIssues = frequencyTables(dfTestIssues)\n",
    "dfTestIssues = diffFeaturesByGroups(dfTestIssues)\n",
    "dfTestIssues = diffFeatures(dfTestIssues)\n",
    "dfTestIssues = createAuxiliaryFeatures(dfTestIssues)\n",
    "print(dfTestIssues.shape)\n",
    "\n",
    "del byAuthorTest, byIssueTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73cd9c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summary', 'pos', 'time', 'created']\n",
      "(1070, 53)\n"
     ]
    }
   ],
   "source": [
    "objectColsTest = [col for col in list(dfTestIssues) if dfTestIssues[col].dtype == \"object\"]\n",
    "objectColsTest.remove(\"summary_l\")\n",
    "objectColsTest.append(\"created\")\n",
    "print(objectColsTest)\n",
    "\n",
    "dfTestIssues.drop(objectColsTest, axis=1, inplace=True)\n",
    "print(dfTestIssues.shape)\n",
    "\n",
    "del objectColsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d3c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 1125)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dfTestIssues = dfTestIssues.merge(tfidfDf[9589:], on=\"id\", how=\"left\").fillna(0)\n",
    "print(dfTestIssues.shape)\n",
    "print(dfTestIssues.isna().sum().sum())\n",
    "\n",
    "dfTestIssues.drop([col for col in list(dfTestIssues) if dfTestIssues[col].dtype == \"object\"], axis=1, inplace=True)\n",
    "dfTestIssues.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43ecefa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1070/1070 [00:04<00:00, 257.80it/s]\n",
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1070/1070 [00:17<00:00, 62.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# LANG MODELS\n",
    "\n",
    "dfTestLang = pd.read_csv(links[\"test\"][\"issues\"])\n",
    "dfTestLang[\"summary\"] = dfTestLang[\"summary\"].str.lower()\n",
    "\n",
    "langModels = [\"cointegrated/rubert-tiny2\", \"cointegrated/LaBSE-en-ru\"]\n",
    "\n",
    "for model in langModels:\n",
    "    dfTestLang = dfTestLang.join(Embeddings(dfTestLang, model, \"summary\", device).apply())\n",
    "\n",
    "dfTestLang.drop([\"created\", \"key\", \"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7b71f",
   "metadata": {},
   "source": [
    "## SUBMIT GENERATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "047917ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 1123)\n",
      "[(766) r2]: 0.2399940768259865\n",
      "[(979) r2]: 0.2422871073023063\n",
      "[(269) r2]: 0.24328626341855686\n",
      "[(970) r2]: 0.23751384108076357\n",
      "[(997) r2]: 0.24606253671141665\n",
      "[(57) r2]: 0.2423468987735531\n",
      "[(785) r2]: 0.24510828130004303\n"
     ]
    }
   ],
   "source": [
    "train, valid = train_test_split(dfTrainIssues, test_size=0.25, shuffle=True, random_state=42)\n",
    "y_train, y_valid = train[\"overall_worklogs\"], valid[\"overall_worklogs\"]\n",
    "train.drop([\"overall_worklogs\"], axis=1, inplace=True)\n",
    "valid.drop([\"overall_worklogs\"], axis=1, inplace=True)\n",
    "allCols = list(train)\n",
    "\n",
    "dfTestIssues = dfTestIssues[allCols]\n",
    "print(dfTestIssues.shape)\n",
    "\n",
    "for _ in range(7):\n",
    "    randomState = np.random.choice(list(range(1000)))\n",
    "    \n",
    "    cb = CatBoostRegressor(iterations=1000, random_seed=randomState, task_type=\"CPU\",\n",
    "                                   eval_metric=\"R2\", use_best_model=True, cat_features=[\"project_id\", \"assignee_id\",\n",
    "                                                                                        \"creator_id\"])\n",
    "    cb.fit(train, y_train, eval_set=[(valid, y_valid)], early_stopping_rounds=100, verbose=0)\n",
    "    \n",
    "    r2 = r2_score(y_valid, cb.predict(valid))\n",
    "    print(f\"[({randomState}) r2]: {r2}\")\n",
    "    \n",
    "    dfId[f\"pred_rs_{randomState}\"] = np.exp(cb.predict(dfTestIssues)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13026f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overall_worklogs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675975</td>\n",
       "      <td>18086.276912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>675972</td>\n",
       "      <td>14303.807374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>675965</td>\n",
       "      <td>7114.926681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>675961</td>\n",
       "      <td>15645.837888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>675955</td>\n",
       "      <td>9209.793517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  overall_worklogs\n",
       "0  675975      18086.276912\n",
       "1  675972      14303.807374\n",
       "2  675965       7114.926681\n",
       "3  675961      15645.837888\n",
       "4  675955       9209.793517"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RsColumns = dfId.columns[1:]\n",
    "dfId[\"overall_worklogs\"] = dfId[RsColumns].mean(axis=1)\n",
    "dfId = dfId[[\"id\", \"overall_worklogs\"]]\n",
    "dfId.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2719e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 1083)\n",
      "[(138) r2]: 0.23121337032741762\n",
      "[(173) r2]: 0.22160960006155717\n",
      "[(902) r2]: 0.22633459430621827\n",
      "[(207) r2]: 0.21121634354664076\n",
      "[(801) r2]: 0.23296610361865955\n",
      "[(326) r2]: 0.2378746287345398\n",
      "[(743) r2]: 0.23583660637297543\n"
     ]
    }
   ],
   "source": [
    "# LANG MODELS\n",
    "dfIdL = dfId.copy()\n",
    "\n",
    "trainL, validL = train_test_split(dfTrainLang, test_size=0.25, shuffle=True, random_state=42)\n",
    "y_trainL, y_validL = trainL[\"overall_worklogs\"], validL[\"overall_worklogs\"]\n",
    "trainL.drop([\"overall_worklogs\"], axis=1, inplace=True)\n",
    "validL.drop([\"overall_worklogs\"], axis=1, inplace=True)\n",
    "allColsL = list(trainL)\n",
    "len(allColsL)\n",
    "\n",
    "dfTestLang = dfTestLang[allColsL]\n",
    "print(dfTestLang.shape)\n",
    "\n",
    "for _ in range(7):\n",
    "    randomState = np.random.choice(list(range(1000)))\n",
    "    \n",
    "    cb = CatBoostRegressor(iterations=1000, random_seed=randomState, task_type=\"CPU\",\n",
    "                                   eval_metric=\"R2\", use_best_model=True, cat_features=[\"project_id\", \"assignee_id\",\n",
    "                                                                                        \"creator_id\"])\n",
    "    cb.fit(trainL, y_trainL, eval_set=[(validL, y_validL)], early_stopping_rounds=100, verbose=0)\n",
    "    \n",
    "    r2L = r2_score(y_validL, cb.predict(validL))\n",
    "    print(f\"[({randomState}) r2]: {r2L}\")\n",
    "    \n",
    "    dfIdL[f\"pred_rs_{randomState}\"] = np.exp(cb.predict(dfTestLang)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21a9550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overall_worklogs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675975</td>\n",
       "      <td>12751.547923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>675972</td>\n",
       "      <td>7357.738941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>675965</td>\n",
       "      <td>8856.748984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>675961</td>\n",
       "      <td>15916.322550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>675955</td>\n",
       "      <td>10427.003697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  overall_worklogs\n",
       "0  675975      12751.547923\n",
       "1  675972       7357.738941\n",
       "2  675965       8856.748984\n",
       "3  675961      15916.322550\n",
       "4  675955      10427.003697"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RsColumnsL = dfIdL.columns[1:]\n",
    "dfIdL[\"overall_worklogs\"] = dfIdL[RsColumnsL].mean(axis=1)\n",
    "dfIdL = dfIdL[[\"id\", \"overall_worklogs\"]]\n",
    "dfIdL.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "425db8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "finDf = dfId.merge(dfIdL, on=\"id\")\n",
    "finDf[\"overall_worklogs\"] = finDf[[\"overall_worklogs_x\", \"overall_worklogs_y\"]].mean(axis=1)\n",
    "finDf[\"overall_worklogs\"] = finDf[\"overall_worklogs\"] * 1.55\n",
    "finDf[[\"id\", \"overall_worklogs\"]].to_csv(\"finSol_f0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef4fde",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 522.85,
   "position": {
    "height": "40px",
    "left": "1223.2px",
    "right": "20px",
    "top": "72px",
    "width": "295px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
